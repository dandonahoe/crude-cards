# Use the official Node.js 20 image as the base for the build stage

FROM node:20-alpine AS builder


# This line allows the agent to run without a configuration file.
# ENV NEW_RELIC_NO_CONFIG_FILE=true

# # Turn this on to enable AI monitoring for your AI application.
# ENV NEW_RELIC_DISTRIBUTED_TRACING_ENABLED=true
# ENV NEW_RELIC_LOG=stdout
# ENV NEW_RELIC_AI_MONITORING_ENABLED=true
# ENV NEW_RELIC_CUSTOM_INSIGHTS_EVENTS_MAX_SAMPLES_STORED=100k
# ENV NEW_RELIC_SPAN_EVENTS_MAX_SAMPLES_STORED=10k


# Set the working directory inside the container to /app
WORKDIR /app

COPY . .

RUN npm install -g pnpm

RUN pnpm install --frozen-lockfile

WORKDIR /app/src/api

RUN pnpm install --frozen-lockfile

WORKDIR /app

# Use the official Node.js 20 image as the base for the runtime stage
FROM node:20-alpine

RUN apk add bash curl

# Install Datadog Agent again in the runtime stage
# DD_API_KEY, DD_SITE, and DD_APM_INSTRUMENTATION_ENABLED are
# Use Gloud Run Env Variables DD_API_KEY
# RUN DD_SITE="us5.datadoghq.com" DD_API_KEY=DD_API_KEY bash  -c "$(curl -L https://install.datadoghq.com/scripts/install_script_agent7.sh)"
RUN DD_SITE="us5.datadoghq.com" DD_APM_INSTRUMENTATION_ENABLED="host" bash -c "DD_API_KEY=${DD_API_KEY} curl -L https://install.datadoghq.com/scripts/install_script_agent7.sh | bash"


RUN docker run -d --cgroupns host --pid host --name dd-agent -v /var/run/docker.sock:/var/run/docker.sock:ro -v /proc/:/host/proc/:ro -v /sys/fs/cgroup/:/host/sys/fs/cgroup:ro -e DD_SITE=<DATADOG_SITE> -e DD_API_KEY=${DD_API_KEY} gcr.io/datadoghq/agent:7

# Set the working directory inside the container to /app
WORKDIR /app

# Copy built files from the builder stage to the current stage
COPY --from=builder /app .

RUN npm install -g pnpm

# Expose port 3000 to the outside world
EXPOSE 8080

# Set environment variable for the port
ENV PORT=8080

# todo - run multiple apps here?
# Command to run the application
CMD ["pnpm", "start:backend"]
